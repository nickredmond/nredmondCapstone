package neuralNetwork;

import java.util.List;
import java.util.Set;

public class BackpropagationTrainer implements INetworkTrainer {

	@Override
	public void trainWithSingleTrainingExample(NeuralNetwork network,
			TrainingExample example) {
		// TODO Auto-generated method stub
		
	}

	@Override
	public void trainWithTrainingSet(NeuralNetwork network,
			Set<TrainingExample> trainingSet) {
		for (TrainingExample nextExample : trainingSet){
			List<Neuron> outputNeurons = network.getOutputLayer().getNeurons();
			calculateOutputErrors(network, nextExample, outputNeurons);
			
			List<NetworkLayer> hiddenLayers = network.getHiddenLayers();
			calculateHiddenErrors(hiddenLayers);
			
			calculateDeltas(hiddenLayers, network.getInputLayer());
		}
	}

	private void calculateHiddenErrors(List<NetworkLayer> hiddenLayers) {
		for (int i = hiddenLayers.size() - 1; i >= 0; i++){
			NetworkLayer currentLayer = hiddenLayers.get(i);
			
			for (Neuron nextNeuron : currentLayer.getNeurons()){
				float errorValue = 0.0f;
				
				for (NeuronConnection nextConnection : nextNeuron.getOutputConnections()){
					errorValue += nextConnection.getWeight() + nextConnection.getConnector().getErrorValue();
				}
				
				nextNeuron.setErrorValue(errorValue);
			}
		}
	}

	private void calculateOutputErrors(NeuralNetwork network,
			TrainingExample nextExample, List<Neuron> outputNeurons) {
		int[] actualOutput = network.getOutputForInput(nextExample.getInput());
		int[] desiredOutput = nextExample.getOutput();
		
		for (int i = 0; i < actualOutput.length; i++){
			float nextErrorValue = (float)(actualOutput[i] - desiredOutput[i]);
			outputNeurons.get(i).setErrorValue(nextErrorValue);
		}
	}

}
